{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mcpenguin/super-mario-64-speedruns-data-collection?scriptVersionId=143235343\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Super Mario 64 Speedruns - Data Collection\n\nThis notebook catalogs the methodology used to obtain data for Super Mario 64 speedrun data from [speedrun.com](https://www.speedrun.com/sm64), and automatically update the corresponding [Kaggle dataset](https://www.kaggle.com/datasets/mcpenguin/super-mario-64-speedruns).\n\nNote that this notebook is easily configurable to obtain speedrun data for other games as well.\n\n## References\n\nI used [this notebook](https://www.kaggle.com/code/nnjjpp/updating-a-dataset-with-a-notebook?scriptVersionId=134546596) as a reference on how to update a dataset with a notebook.\n\n## Some of my other work\n\n### Notebooks\n\n- [Butterfly Image Classification](https://www.kaggle.com/code/mcpenguin/butterfly-classification-efficientnet-87)\n- [Palmer Penguin EDA](https://www.kaggle.com/code/mcpenguin/palmer-archipelago-antarctica-penguin-eda)\n- [Smoking and Drinking EDA + Classification](https://www.kaggle.com/code/mcpenguin/smoking-drinking-prediction-tfdf-71)\n- [World Happiness Data Cleaning + EDA](https://www.kaggle.com/code/mcpenguin/world-happiness-data-cleaning-eda)\n- [Precious Metals Stocks: EDA + Forecasting](https://www.kaggle.com/code/mcpenguin/precious-metals-stocks-eda-and-prediction)\n- [Red Wine Quality EDA + Prediction](https://www.kaggle.com/code/mcpenguin/red-wine-quality-prediction)\n- [Gaia Stellar Classification](https://www.kaggle.com/code/mcpenguin/gaia-stellar-classification-lightgbm-91-acc)\n\n### Datasets\n\n- [The Complete Rollercoasters Dataset](https://www.kaggle.com/datasets/mcpenguin/rollercoasters)\n- [Malaysian COVID-19 Data](https://www.kaggle.com/datasets/mcpenguin/malaysia-covid19)","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries\n\nWe will be using the `srcomapi` Python library, which is a library for the Speedrun.com API.","metadata":{}},{"cell_type":"code","source":"!pip install srcomapi","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:05:01.567527Z","iopub.execute_input":"2023-09-05T15:05:01.568102Z","iopub.status.idle":"2023-09-05T15:05:18.227034Z","shell.execute_reply.started":"2023-09-05T15:05:01.568057Z","shell.execute_reply":"2023-09-05T15:05:18.225664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport requests\nimport json\n\nimport srcomapi\nimport srcomapi.datatypes as srdatatypes\n\nfrom tqdm.autonotebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-05T15:07:00.813149Z","iopub.execute_input":"2023-09-05T15:07:00.81367Z","iopub.status.idle":"2023-09-05T15:07:00.821621Z","shell.execute_reply.started":"2023-09-05T15:07:00.813634Z","shell.execute_reply":"2023-09-05T15:07:00.82013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process Kaggle API Key\n\nTo change/add user secrets, in the notebook editor go to `Add-ons -> Secrets`.","metadata":{}},{"cell_type":"code","source":"if os.path.exists('/root/.kaggle/'):\n    pass\nelse:\n    os.mkdir('/root/.kaggle/')\nkaggle_API_key = UserSecretsClient().get_secret(\"KAGGLE_API_KEY\")\n\nwith open('/root/.kaggle/kaggle.json', 'w') as fid:\n    fid.writelines(f'{{\"username\":\"mcpenguin\",\"key\":\"{kaggle_API_key}\"}}')\n\n!chmod 600 /root/.kaggle/kaggle.json","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:21:55.680214Z","iopub.execute_input":"2023-09-05T15:21:55.681335Z","iopub.status.idle":"2023-09-05T15:21:57.055626Z","shell.execute_reply.started":"2023-09-05T15:21:55.681283Z","shell.execute_reply":"2023-09-05T15:21:57.053606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Obtain Data","metadata":{}},{"cell_type":"markdown","source":"## Initialize Speedrun.com API Library\n\nWe first initialize the Speedrun.com API:","metadata":{}},{"cell_type":"code","source":"SPEEDRUN_API_LINK = \"https://www.speedrun.com/api/v1\"\n\napi = srcomapi.SpeedrunCom();\n# api.debug = 1","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:11.517673Z","iopub.execute_input":"2023-09-05T15:16:11.51827Z","iopub.status.idle":"2023-09-05T15:16:11.528135Z","shell.execute_reply.started":"2023-09-05T15:16:11.518224Z","shell.execute_reply":"2023-09-05T15:16:11.525608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get Game Data\n\nWe can then get the data for `Minecraft: Java Edition`. This notebook is configured in a way so that it should be easily adaptable to get data for other games from Speedrun.com as well.","metadata":{}},{"cell_type":"code","source":"# search for game\ngame_name = \"Super Mario 64\"\n\ngame_search = api.search(srcomapi.datatypes.Game, {\"name\": game_name})\ngame = game_search[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:11.531144Z","iopub.execute_input":"2023-09-05T15:16:11.531637Z","iopub.status.idle":"2023-09-05T15:16:13.259914Z","shell.execute_reply.started":"2023-09-05T15:16:11.531592Z","shell.execute_reply":"2023-09-05T15:16:13.258558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For reference, let's see what the game ID is:","metadata":{}},{"cell_type":"code","source":"game.id","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:13.262216Z","iopub.execute_input":"2023-09-05T15:16:13.26318Z","iopub.status.idle":"2023-09-05T15:16:13.27466Z","shell.execute_reply.started":"2023-09-05T15:16:13.263122Z","shell.execute_reply":"2023-09-05T15:16:13.272926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get Game-Specific \"Variables\"\n\nTo process the game data, we will need to get the variables for Minecraft. To do this, we will use the following `get_variables` function.","metadata":{}},{"cell_type":"code","source":"def get_variables(game):\n    \n    variables_response = api.get(f\"games/{game.id}/variables\")\n    \n    # variable_id_to_name maps variable ids to the names of the variables\n    # and is of type {[variable_id]: [name]}\n    variable_id_to_name = {}\n    # variable_choice_id_to_name maps variable choice ids to the names of the variable choices\n    # and is of type { [variable_id]: {[variable_choice_id]: [name]} }\n    variable_choice_id_to_name = {}\n    \n    for variable_obj in variables_response:\n        variable_id_to_name[variable_obj[\"id\"]] = variable_obj[\"name\"]\n        var_id = variable_obj[\"id\"]\n        variable_choice_id_to_name[var_id] = {}\n        \n        values_response = variable_obj[\"values\"][\"values\"]\n        for value_id, value_obj in values_response.items():\n            variable_choice_id_to_name[var_id][value_id] = value_obj[\"label\"]\n    \n    return variable_id_to_name, variable_choice_id_to_name\n\nvariable_id_to_name_dict, variable_choice_id_to_name_dict = get_variables(game)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:13.277644Z","iopub.execute_input":"2023-09-05T15:16:13.278107Z","iopub.status.idle":"2023-09-05T15:16:13.424437Z","shell.execute_reply.started":"2023-09-05T15:16:13.278072Z","shell.execute_reply":"2023-09-05T15:16:13.423001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For reference, let's see what each of these dictionaries look like:","metadata":{}},{"cell_type":"code","source":"variable_id_to_name_dict","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:13.426464Z","iopub.execute_input":"2023-09-05T15:16:13.426967Z","iopub.status.idle":"2023-09-05T15:16:13.43556Z","shell.execute_reply.started":"2023-09-05T15:16:13.426925Z","shell.execute_reply":"2023-09-05T15:16:13.434367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"variable_choice_id_to_name_dict","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:13.437305Z","iopub.execute_input":"2023-09-05T15:16:13.437736Z","iopub.status.idle":"2023-09-05T15:16:13.451962Z","shell.execute_reply.started":"2023-09-05T15:16:13.437688Z","shell.execute_reply":"2023-09-05T15:16:13.449915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get Raw Data\n\nWe now get the raw data from the API and store them in a dictionary:","metadata":{}},{"cell_type":"code","source":"# only consider star categories\ncategories = [\"0 Star\", \"1 Star\", \"16 Star\", \"70 Star\", \"120 Star\"]\n\n# we need a limit, as the API might return a 504 error\n# if there is too much data (> 1k rows)\n# also for some reason the python API library kind of self-destructs for this function\n# so we just use the API directly instead :)\ndef get_category_data(game, category, limit=500, level=None):\n    if level is None:\n        link = f\"{SPEEDRUN_API_LINK}/leaderboards/{game.id}/category/{category.id}?embed=variables,players&top={limit}\"\n    else:\n        link = f\"{SPEEDRUN_API_LINK}/leaderboards/{game.id}/level/{level.id}/{category.id}?embed=variables,players&top={limit}\"\n    response = requests.get(link)\n    result = response.json()[\"data\"]\n    return result\n    \n# {[category name]: [list of runs]}\nraw_runs = {}\npbar = tqdm([category for category in game.categories if category.name in categories])\n\nfor category in pbar:\n    category_name = category.name\n    pbar.set_postfix(category=category_name)\n    \n    if not category.name in raw_runs:\n        raw_runs[category.name] = {}\n\n    if category.type == 'per-level':\n        for level in game.levels:\n            raw_runs[category.name][level.name] = get_category_data(game, category, level)\n    else:\n        raw_runs[category.name] = get_category_data(game, category)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:13.453814Z","iopub.execute_input":"2023-09-05T15:16:13.454185Z","iopub.status.idle":"2023-09-05T15:16:59.553881Z","shell.execute_reply.started":"2023-09-05T15:16:13.454153Z","shell.execute_reply":"2023-09-05T15:16:59.552488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions to Process Data\n\nWe now define some helper functions we will use to process the raw runs data.","metadata":{}},{"cell_type":"code","source":"# process run\ndef process_run(run, player_data):\n    verified_key = \"kn04ewol\"\n    platform_key = \"e8m7em86\"\n    \n    # get player data\n    player_id = run[\"run\"][\"players\"][0].get(\"id\", None)\n    if player_id is not None:\n        raw_player_data = player_data[player_id]\n        player_name = raw_player_data[\"names\"][\"international\"]\n        location = raw_player_data[\"location\"]\n        if location is not None:\n            location = location[\"country\"][\"names\"][\"international\"]\n        player_country = location\n    else:\n        player_name = player_country = None\n    \n    result = {\n        # run id\n        \"id\": run[\"run\"][\"id\"],\n        # leaderboard place\n        \"place\": run[\"place\"],\n        # link to speedrun\n        \"speedrun_link\": run[\"run\"][\"weblink\"],\n        # submitted date\n        \"submitted_date\": run[\"run\"][\"submitted\"],\n        # primary time (seconds)\n        \"primary_time_seconds\": run[\"run\"][\"times\"][\"primary_t\"],\n        # real time (seconds)\n        \"real_time_seconds\": run[\"run\"][\"times\"][\"realtime_t\"],\n        # player id\n        \"player_id\": player_id,\n        # player name\n        \"player_name\": player_name,\n        # player country\n        \"player_country\": player_country,\n        # platform\n        \"platform\": variable_choice_id_to_name_dict[platform_key][run[\"run\"][\"values\"][platform_key]],\n        # verified\n        \"verified\": variable_choice_id_to_name_dict[verified_key][run[\"run\"][\"values\"][verified_key]],\n    }\n    return result\n\n# raw_runs_data = {[category]: [runs]}\ndef process_raw_runs_data(raw_runs_data):\n    # cleaned_runs = {[category]: [runs]}\n    cleaned_runs_data = {}\n    \n    for category, category_obj in raw_runs_data.items():\n        cleaned_runs = []\n        raw_runs = category_obj[\"runs\"]\n        \n        player_data_list = category_obj[\"players\"][\"data\"]\n        player_data = {data.get(\"id\"): data for data in player_data_list}\n        \n        print(f\"Processing raw runs data for category {category}\")\n        pbar = tqdm(raw_runs)\n        for raw_run in pbar:\n            try:\n                cleaned_run = process_run(raw_run, player_data)\n                cleaned_runs.append(cleaned_run)\n            except Exception as e:\n                print(\"could not process run:\")\n                print(raw_run)\n                print('error:')\n                print(e)\n        cleaned_runs_data[category] = cleaned_runs\n    return cleaned_runs_data","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:59.555513Z","iopub.execute_input":"2023-09-05T15:16:59.556021Z","iopub.status.idle":"2023-09-05T15:16:59.573398Z","shell.execute_reply.started":"2023-09-05T15:16:59.555973Z","shell.execute_reply":"2023-09-05T15:16:59.571525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process Raw Runs Data\n\nWe can now clean the raw runs data, so that we will be able to process it into a CSV.","metadata":{}},{"cell_type":"code","source":"cleaned_runs_data = process_raw_runs_data(raw_runs)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:59.575584Z","iopub.execute_input":"2023-09-05T15:16:59.576125Z","iopub.status.idle":"2023-09-05T15:16:59.715404Z","shell.execute_reply.started":"2023-09-05T15:16:59.576078Z","shell.execute_reply":"2023-09-05T15:16:59.714286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert Data into DataFrames","metadata":{}},{"cell_type":"markdown","source":"We can now convert our cleaned runs data into data-frames for exporting/upload.","metadata":{}},{"cell_type":"code","source":"# {category: df}\ndfs = {}\n\nfor category, cleaned_runs in cleaned_runs_data.items():\n    dfs[category] = pd.DataFrame.from_records(cleaned_runs)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:59.718579Z","iopub.execute_input":"2023-09-05T15:16:59.719565Z","iopub.status.idle":"2023-09-05T15:16:59.749615Z","shell.execute_reply.started":"2023-09-05T15:16:59.719531Z","shell.execute_reply":"2023-09-05T15:16:59.748035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see how these look like:","metadata":{}},{"cell_type":"code","source":"dfs[\"70 Star\"].head()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:59.751207Z","iopub.execute_input":"2023-09-05T15:16:59.751554Z","iopub.status.idle":"2023-09-05T15:16:59.779532Z","shell.execute_reply.started":"2023-09-05T15:16:59.751524Z","shell.execute_reply":"2023-09-05T15:16:59.778153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save DataFrames to Files\n\nWe can then save our dataframes to files.","metadata":{}},{"cell_type":"code","source":"for category, df in dfs.items():\n    filename = f\"/kaggle/working/data_{category}.csv\"\n    df.to_csv(filename)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:59.781825Z","iopub.execute_input":"2023-09-05T15:16:59.782273Z","iopub.status.idle":"2023-09-05T15:16:59.833253Z","shell.execute_reply.started":"2023-09-05T15:16:59.782237Z","shell.execute_reply":"2023-09-05T15:16:59.83146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Re-Upload Files to Kaggle","metadata":{}},{"cell_type":"markdown","source":"## Define Metadata","metadata":{}},{"cell_type":"code","source":"metadata = {\n    \"id\": \"mcpenguin/super-mario-64-speedruns\",\n    \"title\": \"New Update\"\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:16:59.835032Z","iopub.execute_input":"2023-09-05T15:16:59.835539Z","iopub.status.idle":"2023-09-05T15:16:59.840727Z","shell.execute_reply.started":"2023-09-05T15:16:59.835504Z","shell.execute_reply":"2023-09-05T15:16:59.839333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/dataset-metadata.json', 'w') as json_fid:\n    json_fid.write(json.dumps(metadata))","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:17:56.398098Z","iopub.execute_input":"2023-09-05T15:17:56.398522Z","iopub.status.idle":"2023-09-05T15:17:56.405242Z","shell.execute_reply.started":"2023-09-05T15:17:56.398492Z","shell.execute_reply":"2023-09-05T15:17:56.40409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Push New Metadata","metadata":{}},{"cell_type":"code","source":"!kaggle datasets download mcpenguin/super-mario-64-speedruns","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:31:58.098687Z","iopub.execute_input":"2023-09-05T15:31:58.099828Z","iopub.status.idle":"2023-09-05T15:32:00.298034Z","shell.execute_reply.started":"2023-09-05T15:31:58.099745Z","shell.execute_reply":"2023-09-05T15:32:00.296276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.remove(\"/kaggle/working/super-mario-64-speedruns.zip\")","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:32:02.787851Z","iopub.execute_input":"2023-09-05T15:32:02.78934Z","iopub.status.idle":"2023-09-05T15:32:02.797183Z","shell.execute_reply.started":"2023-09-05T15:32:02.78927Z","shell.execute_reply":"2023-09-05T15:32:02.795617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets version -p /kaggle/working -m \"Updated data\"","metadata":{"execution":{"iopub.status.busy":"2023-09-05T15:32:05.176914Z","iopub.execute_input":"2023-09-05T15:32:05.177365Z","iopub.status.idle":"2023-09-05T15:32:20.437485Z","shell.execute_reply.started":"2023-09-05T15:32:05.177334Z","shell.execute_reply":"2023-09-05T15:32:20.436308Z"},"trusted":true},"execution_count":null,"outputs":[]}]}