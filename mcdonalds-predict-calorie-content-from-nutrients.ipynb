{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mcpenguin/mcdonalds-predict-calorie-content-from-nutrients?scriptVersionId=143235089\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# McDonalds Dataset - Predict Calorie Content from Nutrient Composition\n\nIn this notebook, we will try to predict the calorie count of McDonalds food items from their nutritional composition.","metadata":{}},{"cell_type":"markdown","source":"# 0 Import Libraries Needed","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch # only to chekc if gpu acceleration is available\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-10T19:43:53.83522Z","iopub.execute_input":"2023-08-10T19:43:53.835755Z","iopub.status.idle":"2023-08-10T19:43:59.687948Z","shell.execute_reply.started":"2023-08-10T19:43:53.835719Z","shell.execute_reply":"2023-08-10T19:43:59.686978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1 Load Data\n\nWe first load our dataset:","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"../input/mcdonalds-nutrition\"\n\ndf = pd.read_csv(os.path.join(DATA_DIR, \"McDonaldsMenuNutrition.csv\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:43:59.690095Z","iopub.execute_input":"2023-08-10T19:43:59.690776Z","iopub.status.idle":"2023-08-10T19:43:59.714471Z","shell.execute_reply.started":"2023-08-10T19:43:59.690739Z","shell.execute_reply":"2023-08-10T19:43:59.713579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 First Look at Data\n\nAs a first step, let us see how the data looks like without any feature engineering:","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:43:59.71557Z","iopub.execute_input":"2023-08-10T19:43:59.715898Z","iopub.status.idle":"2023-08-10T19:43:59.745632Z","shell.execute_reply.started":"2023-08-10T19:43:59.715865Z","shell.execute_reply":"2023-08-10T19:43:59.744546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The column names are a little messy, so one potential step we should do before further anlaysis is to clean these column names up to make them easier for analysis.\n\nMost of these attributes are self-explanatory, but I had never encountered the concept of \"Weight Watchers\" points before, so I wanted to clarify what they entail. After a quick Google search, it seems like the Weight Watcher points quantifies the potential of how significant a food is to make you gain weight, with high-sugar foods receiving a high point value, whereas high-protein/high-fiber foods receive a low point value. You can find more information through this link: https://www.weightwatchers.com/au/how-it-works/points","metadata":{}},{"cell_type":"code","source":"print(\"Size of dataset:\", df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:43:59.748499Z","iopub.execute_input":"2023-08-10T19:43:59.74883Z","iopub.status.idle":"2023-08-10T19:43:59.753345Z","shell.execute_reply.started":"2023-08-10T19:43:59.7488Z","shell.execute_reply":"2023-08-10T19:43:59.752443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's also check for any missing values in the dataset:","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:43:59.75484Z","iopub.execute_input":"2023-08-10T19:43:59.7555Z","iopub.status.idle":"2023-08-10T19:43:59.76982Z","shell.execute_reply.started":"2023-08-10T19:43:59.755465Z","shell.execute_reply":"2023-08-10T19:43:59.768649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that there are some missing values, including data where the Calories count is missing. We will have to exclude these examples from our training.\n\nBefore we proceed with any further analysis, let's clean up the column names to get rid of the newline character `\\n` and expand any abbreviations to improve clarity:","metadata":{}},{"cell_type":"code","source":"df = df.rename({\n    \"Calories from\\nFat\": \"Calories From Fat\",\n    \"Total Fat\\n(g)\": \"Total Fat (g)\",\n    \"Saturated Fat\\n(g)\": \"Saturated Fat (g)\",\n    \"Trans Fat\\n(g)\": \"Trans Fat (g)\",\n    \"Cholesterol\\n(mg)\": \"Cholesterol (mg)\",\n    \"Sodium \\n(mg)\": \"Sodium (mg)\",\n    \"Carbs\\n(g)\": \"Carbohydrates (g)\",\n    \"Fiber\\n(g)\": \"Fiber (g)\",\n    \"Sugars\\n(g)\": \"Sugars (g)\",\n    \"Protein\\n(g)\": \"Protein (g)\",\n    \"Weight Watchers\\nPnts\": \"Weight Watchers Points\"\n}, axis='columns')","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:43:59.771791Z","iopub.execute_input":"2023-08-10T19:43:59.772231Z","iopub.status.idle":"2023-08-10T19:43:59.779011Z","shell.execute_reply.started":"2023-08-10T19:43:59.7722Z","shell.execute_reply":"2023-08-10T19:43:59.778046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's examine how the dataset looks like now:","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:43:59.78052Z","iopub.execute_input":"2023-08-10T19:43:59.78121Z","iopub.status.idle":"2023-08-10T19:43:59.805089Z","shell.execute_reply.started":"2023-08-10T19:43:59.781177Z","shell.execute_reply":"2023-08-10T19:43:59.804243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's also examine the types of the columns to check they align with our intuitions:","metadata":{}},{"cell_type":"markdown","source":"Next, an attribute that might be of interest is to classify the food items by their categories - for example, Burgers, Sides, Desserts, etc. To do this, let's visualize the full dataset to see all the different items present:","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\n\ndf","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-10T19:43:59.806526Z","iopub.execute_input":"2023-08-10T19:43:59.807117Z","iopub.status.idle":"2023-08-10T19:44:00.211506Z","shell.execute_reply.started":"2023-08-10T19:43:59.807086Z","shell.execute_reply":"2023-08-10T19:44:00.210579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this, we can pick out a few key observations:\n\n* The data points are roughly arranged in order of category, in the sense that similarly grouped items are grouped together in the dataset. This makes  categorizing them much easier.\n\n* Many items in the dataset have sizes attributed to them, like **Small, Medium and Large**. One possible feature we could add is a `Size` variate by extracting this information from the item names. However, different items with the same size might still have massively different calorie counts, due to the nature of the food item (e.g. think of the discrepancy between a Large Coke Zero vs. a Large Latte).\n\n* The item **Salad Dressings** (row 64) has basically no information. As such, we can just remove this from the dataset entirely.\n\n* The item **Hamburger Happy Meal** has a `Saturated Fat (g)` value of \"5.5 g\", which is a string. We should convert this to the corresponding numeric value and change the `dtype` of the associated column to be numeric.","metadata":{}},{"cell_type":"code","source":"df.loc[df[\"Item\"] == \"Hamburger Happy Meal\", \"Saturated Fat (g)\"] = 5.5\ndf[\"Saturated Fat (g)\"] = df[\"Saturated Fat (g)\"].astype(\"float64\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:44:57.704783Z","iopub.execute_input":"2023-08-10T19:44:57.705167Z","iopub.status.idle":"2023-08-10T19:44:57.712066Z","shell.execute_reply.started":"2023-08-10T19:44:57.705135Z","shell.execute_reply":"2023-08-10T19:44:57.711064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3 Graphical Attributes\n\nLet's plot histograms for all the explanatory variates:","metadata":{}},{"cell_type":"code","source":"df.hist(bins=30, figsize=(15, 10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:45:07.565417Z","iopub.execute_input":"2023-08-10T19:45:07.565766Z","iopub.status.idle":"2023-08-10T19:45:10.350964Z","shell.execute_reply.started":"2023-08-10T19:45:07.565733Z","shell.execute_reply":"2023-08-10T19:45:10.350024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also plot the correlation matrix between all the different variates:","metadata":{}},{"cell_type":"code","source":"corr = df.corr(numeric_only=True)\n\nsns.heatmap(corr)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:45:10.353122Z","iopub.execute_input":"2023-08-10T19:45:10.353762Z","iopub.status.idle":"2023-08-10T19:45:10.818621Z","shell.execute_reply.started":"2023-08-10T19:45:10.353726Z","shell.execute_reply":"2023-08-10T19:45:10.817514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In particular, as we want to predict the `Calories` variate, we should also find the highest correlating explanatory variates with this:","metadata":{}},{"cell_type":"code","source":"corr[\"Calories\"].sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:45:10.820396Z","iopub.execute_input":"2023-08-10T19:45:10.820742Z","iopub.status.idle":"2023-08-10T19:45:10.83235Z","shell.execute_reply.started":"2023-08-10T19:45:10.820713Z","shell.execute_reply":"2023-08-10T19:45:10.831146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems like the weight watchers points a food item has correlates very strongly with its calorie count, which makes sense given the nature of weight watcher points. Unsurprisingly, the three main food nutrients - Carbohydrates, Protein and Fat - also constitute significant correlations with a food's calorie count.","metadata":{}},{"cell_type":"markdown","source":"# 4 Feature Engineering\n\nWe are now ready to add some features to our dataset that might be useful in our predictive analysis.\n\nFirstly, let's add categories to the dataset. These were decided by me by observing the dataset, and might not reflect the actual McDonalds' categories, but they should serve as a good basis:","metadata":{}},{"cell_type":"code","source":"# default \"other\", which will include toppings and sauces\ndf[\"Category\"] = \"Other\"\n\ndf.loc[0:15, \"Category\"] = \"Burgers\"\ndf.loc[15:22, \"Category\"] = \"Sandwiches\"\ndf.loc[22:34, \"Category\"] = \"Wraps\"\ndf.loc[34:36, \"Category\"] = \"Fries\"\ndf.loc[39:42, \"Category\"] = \"McNuggets\"\ndf.loc[46:48, \"Category\"] = \"Chicken Strips\"\ndf.loc[52:62, \"Category\"] = \"Salads\"\ndf.loc[70:104, \"Category\"] = \"Breakfast\"\ndf.loc[105:131, \"Category\"] = \"Desserts\"\ndf.loc[131:145, \"Category\"] = \"Milkshakes\"\ndf.loc[149:175, \"Category\"] = \"Soft Drinks\"\ndf.loc[182:324, \"Category\"] = \"Coffees, Teas and Hot Chocolate\"\ndf.loc[325:330, \"Category\"] = \"Smoothies\"","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:45:10.835721Z","iopub.execute_input":"2023-08-10T19:45:10.836122Z","iopub.status.idle":"2023-08-10T19:45:10.85008Z","shell.execute_reply.started":"2023-08-10T19:45:10.836088Z","shell.execute_reply":"2023-08-10T19:45:10.84905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Category\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:45:10.851638Z","iopub.execute_input":"2023-08-10T19:45:10.852763Z","iopub.status.idle":"2023-08-10T19:45:10.870635Z","shell.execute_reply.started":"2023-08-10T19:45:10.85269Z","shell.execute_reply":"2023-08-10T19:45:10.8696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will need to convert these into one-hot encodings when we model this dataset, so let us do so:","metadata":{}},{"cell_type":"code","source":"df = pd.get_dummies(df, columns=[\"Category\"])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:45:10.872288Z","iopub.execute_input":"2023-08-10T19:45:10.872628Z","iopub.status.idle":"2023-08-10T19:45:10.904851Z","shell.execute_reply.started":"2023-08-10T19:45:10.872598Z","shell.execute_reply":"2023-08-10T19:45:10.90398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also need to deal with missing values. Since we are only predicting a food's calorie count with its nutritional breakup, we do not really care about any missing Weight Watcher points values. If a nutritional value is NA, I will replace it with 0.","metadata":{}},{"cell_type":"code","source":"df = df.fillna(0)\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T19:45:10.906274Z","iopub.execute_input":"2023-08-10T19:45:10.906622Z","iopub.status.idle":"2023-08-10T19:45:10.916263Z","shell.execute_reply.started":"2023-08-10T19:45:10.906589Z","shell.execute_reply":"2023-08-10T19:45:10.915151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5 Modelling\n\nTo model the calorie count of the various food items, we will use gradient boosting regression.\n\nWe first train our model:","metadata":{}},{"cell_type":"code","source":"X = df.loc[:, df.columns != \"Calories\"]\ny = df[\"Calories\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n\n_X_train = X_train.drop([\"Item\", \"Weight Watchers Points\"], axis=1)\n_X_test = X_test.drop([\"Item\", \"Weight Watchers Points\"], axis=1)\n\ndtrain_reg = xgb.DMatrix(_X_train, y_train, enable_categorical=True)\ndtest_reg = xgb.DMatrix(_X_test, y_test, enable_categorical=True)\n\n# define parameters for xgboost regression\nif torch.cuda.is_available():\n    tree_method = \"gpu_hist\"\nelse:\n    tree_method = \"hist\"\n\nparams = {\"objective\": \"reg:squarederror\", \"tree_method\": tree_method}\nmodel = xgb.train(\n   params = params,\n   dtrain = dtrain_reg,\n   num_boost_round = 100,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:02:19.843473Z","iopub.execute_input":"2023-08-10T20:02:19.843908Z","iopub.status.idle":"2023-08-10T20:02:20.055909Z","shell.execute_reply.started":"2023-08-10T20:02:19.843876Z","shell.execute_reply":"2023-08-10T20:02:20.054951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are now ready to predict on our test set.","metadata":{}},{"cell_type":"markdown","source":"# 6 Prediction","metadata":{}},{"cell_type":"markdown","source":"Firstly, we initialize a results table:","metadata":{}},{"cell_type":"code","source":"results = pd.DataFrame({\"Item\": X_test[\"Item\"], \"Calories\": y_test})\nresults = results.rename({\"Calories\": \"Actual Calories\"}, axis='columns')\nresults.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:02:31.57115Z","iopub.execute_input":"2023-08-10T20:02:31.571571Z","iopub.status.idle":"2023-08-10T20:02:31.591073Z","shell.execute_reply.started":"2023-08-10T20:02:31.571535Z","shell.execute_reply":"2023-08-10T20:02:31.589894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we can load in our predictions:","metadata":{}},{"cell_type":"code","source":"pred = model.predict(dtest_reg)\nresults[\"Predicted Results\"] = pred\nresults.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:02:31.592895Z","iopub.execute_input":"2023-08-10T20:02:31.595077Z","iopub.status.idle":"2023-08-10T20:02:31.613725Z","shell.execute_reply.started":"2023-08-10T20:02:31.595042Z","shell.execute_reply":"2023-08-10T20:02:31.612701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To quantify the error between the actual and predicted values, we can use the **Mean Squared Error (MSE)** between the values.","metadata":{}},{"cell_type":"code","source":"mean_squared_error(y_test, pred)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:03:09.838641Z","iopub.execute_input":"2023-08-10T20:03:09.839128Z","iopub.status.idle":"2023-08-10T20:03:09.846726Z","shell.execute_reply.started":"2023-08-10T20:03:09.839099Z","shell.execute_reply":"2023-08-10T20:03:09.845768Z"},"trusted":true},"execution_count":null,"outputs":[]}]}